{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import logging\n",
    "import joblib\n",
    "import shap\n",
    "import optuna\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"model_training.log\"), logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Load processed data from CSV files\n",
    "def load_processed_data():\n",
    "    try:\n",
    "        cctv_data = pd.read_csv('processed_cctv_data.csv')\n",
    "        access_data = pd.read_csv('processed_access_data.csv')\n",
    "        intercom_data = pd.read_csv('processed_intercom_data.csv')\n",
    "        logging.info(\"Successfully loaded processed data.\")\n",
    "        return cctv_data, access_data, intercom_data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Data split into features and labels\n",
    "def split_data(cctv_data):\n",
    "    try:\n",
    "        X = cctv_data[['motion_detected', 'is_online', 'hour_of_day']]\n",
    "        y = cctv_data['label_failure']\n",
    "        logging.info(\"Data successfully split into features and labels.\")\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error splitting data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to handle class imbalance with SMOTE\n",
    "def handle_imbalance(X_train, y_train):\n",
    "    try:\n",
    "        logging.info(\"Handling class imbalance using SMOTE...\")\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "        logging.info(f\"Class distribution after SMOTE: {np.bincount(y_res)}\")\n",
    "        return X_res, y_res\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during imbalance handling: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to visualize data distribution\n",
    "def plot_data_distribution(y):\n",
    "    sns.countplot(y)\n",
    "    plt.title(\"Data Distribution (Failures vs Non-Failures)\")\n",
    "    plt.xlabel(\"Failure (1 = Yes, 0 = No)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Optuna objective function for hyperparameter tuning\n",
    "def optuna_rf_objective(trial, X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 50),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, **param_grid)\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    scores = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        X_t, X_v = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_t, y_v = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        rf.fit(X_t, y_t)\n",
    "        y_pred = rf.predict(X_v)\n",
    "        scores.append(accuracy_score(y_v, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Optuna hyperparameter tuning\n",
    "def tune_random_forest_optuna(X_train, y_train):\n",
    "    logging.info(\"Tuning Random Forest with Optuna...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: optuna_rf_objective(trial, X_train, y_train), n_trials=50)\n",
    "\n",
    "    logging.info(f\"Best Random Forest parameters: {study.best_params}\")\n",
    "    best_params = study.best_params\n",
    "    rf_best = RandomForestClassifier(random_state=42, **best_params)\n",
    "    rf_best.fit(X_train, y_train)\n",
    "    \n",
    "    return rf_best\n",
    "\n",
    "# Train Logistic Regression with class weighting for imbalance\n",
    "def train_logistic_regression(X_train, y_train):\n",
    "    logging.info(\"Training Logistic Regression with class weighting...\")\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    lr = LogisticRegression(max_iter=1000, random_state=42, class_weight=dict(enumerate(class_weights)))\n",
    "    lr.fit(X_train, y_train)\n",
    "    return lr\n",
    "\n",
    "# Model evaluation metrics\n",
    "def evaluate_model(y_true, y_pred, y_prob):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    logging.info(f\"Model Evaluation:\\nAccuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# Confusion matrix visualization\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Failure', 'Failure'], yticklabels=['Non-Failure', 'Failure'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ROC curve visualization\n",
    "def plot_roc_curve(y_true, y_prob):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_score(y_true, y_prob))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# SHAP-based model interpretability\n",
    "def explain_model_with_shap(model, X_train):\n",
    "    logging.info(\"Generating SHAP values for model interpretability...\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    shap.summary_plot(shap_values[1], X_train, feature_names=X_train.columns)\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    try:\n",
    "        # Handle class imbalance\n",
    "        X_resampled, y_resampled = handle_imbalance(X_train, y_train)\n",
    "\n",
    "        # Train Random Forest with Optuna tuning\n",
    "        rf_best = tune_random_forest_optuna(X_resampled, y_resampled)\n",
    "        \n",
    "        # Train Logistic Regression\n",
    "        lr_model = train_logistic_regression(X_resampled, y_resampled)\n",
    "\n",
    "        # Predictions for Random Forest\n",
    "        y_pred_rf = rf_best.predict(X_test)\n",
    "        y_prob_rf = rf_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Predictions for Logistic Regression\n",
    "        y_pred_lr = lr_model.predict(X_test)\n",
    "        y_prob_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Evaluate Random Forest\n",
    "        logging.info(\"Evaluating Random Forest...\")\n",
    "        rf_metrics = evaluate_model(y_test, y_pred_rf, y_prob_rf)\n",
    "        plot_confusion_matrix(y_test, y_pred_rf)\n",
    "        plot_roc_curve(y_test, y_prob_rf)\n",
    "\n",
    "        # SHAP explanations for Random Forest\n",
    "        explain_model_with_shap(rf_best, X_train)\n",
    "\n",
    "        # Evaluate Logistic Regression\n",
    "        logging.info(\"Evaluating Logistic Regression...\")\n",
    "        lr_metrics = evaluate_model(y_test, y_pred_lr, y_prob_lr)\n",
    "        plot_confusion_matrix(y_test, y_pred_lr)\n",
    "        plot_roc_curve(y_test, y_prob_lr)\n",
    "\n",
    "        # Save best models\n",
    "        joblib.dump(rf_best, 'best_random_forest_model.pkl')\n",
    "        joblib.dump(lr_model, 'logistic_regression_model.pkl')\n",
    "        logging.info(\"Models successfully saved.\")\n",
    "\n",
    "        return rf_metrics, lr_metrics\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during model training and evaluation: {e}\")\n",
    "        raise\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    try:\n",
    "        # Load and split the data\n",
    "        cctv_data, access_data, intercom_data = load_processed_data()\n",
    "        X, y = split_data(cctv_data)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        # Plot data distribution\n",
    "        plot_data_distribution(y)\n",
    "\n",
    "        # Train and evaluate the models\n",
    "        rf_metrics, lr_metrics = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        logging.info(f\"Random Forest Metrics: {rf_metrics}\")\n",
    "        logging.info(f\"Logistic Regression Metrics: {lr_metrics}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in main function: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
